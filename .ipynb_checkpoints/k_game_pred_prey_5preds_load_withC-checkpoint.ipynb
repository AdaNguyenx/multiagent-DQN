{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:03,058] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:03,132] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:03,653] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:03,817] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:04,282] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:04,353] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:04,858] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:04,944] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:05,518] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:05,590] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-10w/model-5pred-2cues-500trials-10weight-2603626.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:39:07,629] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-10w/model-5pred-2cues-500trials-10weight-2603626.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6\n",
      "16\n",
      "26\n",
      "36\n",
      "43\n",
      "51\n",
      "61\n",
      "65\n",
      "70\n",
      "76\n",
      "86\n",
      "96\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds10-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds10-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds10-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds10-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds10-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-10w/model-5pred-2cues-500trials-10weight-2603626.ckpt'\n",
    "REPLAY_RE = '5preds-10w/replay-5pred-2cues-500trials-10weight-2603626.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:35,111] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:35,183] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:35,592] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:35,665] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:36,083] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:36,161] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:36,721] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:36,793] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:37,210] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:37,279] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-40w/model-5pred-2cues-500trials-40weight-579358.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:52:39,202] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-40w/model-5pred-2cues-500trials-40weight-579358.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "22\n",
      "46\n",
      "73\n",
      "96\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds40-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds40-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds40-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds40-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds40-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-40w/model-5pred-2cues-500trials-40weight-579358.ckpt'\n",
    "REPLAY_RE = '5preds-40w/replay-5pred-2cues-500trials-40weight-579358.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:01,962] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:02,028] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:02,446] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:02,511] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:02,935] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:03,007] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:03,425] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:03,499] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:03,930] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:04,012] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-50w/model-5pred-2cues-500trials-50weight-516364.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 03:57:05,995] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-50w/model-5pred-2cues-500trials-50weight-516364.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "17\n",
      "50\n",
      "75\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds50-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds50-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds50-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds50-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds50-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-50w/model-5pred-2cues-500trials-50weight-516364.ckpt'\n",
    "REPLAY_RE = '5preds-50w/replay-5pred-2cues-500trials-50weight-516364.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:56,327] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:56,393] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:56,810] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:56,876] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:57,291] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:57,363] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:57,792] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:57,860] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:58,277] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:00:58,345] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-60w/model-5pred-2cues-500trials-60weight-343942.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:01:00,407] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-60w/model-5pred-2cues-500trials-60weight-343942.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "17\n",
      "40\n",
      "81\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds60-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds60-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds60-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds60-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds60-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-60w/model-5pred-2cues-500trials-60weight-343942.ckpt'\n",
    "REPLAY_RE = '5preds-60w/replay-5pred-2cues-500trials-60weight-343942.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds70-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds70-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds70-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds70-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds70-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-70w/model-5pred-2cues-500trials-70weight-271102.ckpt'\n",
    "REPLAY_RE = '5preds-70w/replay-5pred-2cues-500trials-70weight-271102.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:54,338] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:54,408] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:54,813] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:54,880] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:55,312] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:55,381] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:55,804] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:55,868] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:56,293] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:56,374] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-80w/model-5pred-2cues-500trials-80weight-238297.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:04:58,493] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-80w/model-5pred-2cues-500trials-80weight-238297.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "31\n",
      "62\n",
      "92\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds80-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds80-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds80-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds80-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds80-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-80w/model-5pred-2cues-500trials-80weight-238297.ckpt'\n",
    "REPLAY_RE = '5preds-80w/replay-5pred-2cues-500trials-80weight-238297.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:30,329] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:30,395] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:30,810] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:30,875] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:31,290] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:31,359] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:31,784] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:31,853] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:32,287] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:32,364] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-90w/model-5pred-2cues-500trials-90weight-180703.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:08:34,112] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-90w/model-5pred-2cues-500trials-90weight-180703.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "33\n",
      "58\n",
      "97\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds90-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds90-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds90-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds90-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds90-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-90w/model-5pred-2cues-500trials-90weight-180703.ckpt'\n",
    "REPLAY_RE = '5preds-90w/replay-5pred-2cues-500trials-90weight-180703.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:53,502] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:53,569] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:53,974] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:54,041] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:54,462] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:54,530] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:54,951] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:55,019] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:55,446] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:55,529] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-free/model-5pred-2cues-500trials-189205.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:11:57,275] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/5preds-free/model-5pred-2cues-500trials-189205.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "36\n",
      "59\n",
      "94\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# doing stuff\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5preds100-load-100weight-c'\n",
    "REPLAY_NAME = 'replay-5preds100-load-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5preds100-load-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5preds100-load-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5preds100-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = '5preds-free/model-5pred-2cues-500trials-189205.ckpt'\n",
    "REPLAY_RE = '5preds-free/replay-5pred-2cues-500trials-189205.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE \n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:16,229] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:16,294] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:16,713] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:16,782] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:17,193] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:17,259] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:17,679] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:17,750] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:18,185] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:18,257] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-0/model-1pred-2cues-500trials-340708.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:19,630] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-0/model-1pred-2cues-500trials-340708.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-1/model-1pred-2cues-500trials-1-361393.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:20,476] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-1/model-1pred-2cues-500trials-1-361393.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-2/model-1pred-2cues-500trials-2-327760.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:21,334] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-2/model-1pred-2cues-500trials-2-327760.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-3/model-1pred-2cues-500trials-3-209602.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:22,243] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-3/model-1pred-2cues-500trials-3-209602.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-4/model-1pred-2cues-500trials-4-361147.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-26 04:15:23,190] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-4/model-1pred-2cues-500trials-4-361147.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "48\n",
      "95\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# reset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule\n",
    "tf.reset_default_graph()\n",
    "\n",
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5indeps-100weight-c'\n",
    "REPLAY_NAME = 'replay-5indeps-100weight-c'\n",
    "ELAPSE_NAME = 'elapse-5indeps-100weight-c'\n",
    "REWARDS_NAME = 'rewards-5indeps-100weight-c'\n",
    "COLLISIONS_NAME = 'collsions-5indeps-load-100weight-c'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE_0 = 'independent-0/model-1pred-2cues-500trials-340708.ckpt'\n",
    "REPLAY_RE_0 = 'independent-0/replay-1pred-2cues-500trials-340708.pkl'\n",
    "MODEL_RE_1 = 'independent-1/model-1pred-2cues-500trials-1-361393.ckpt'\n",
    "REPLAY_RE_1 = 'independent-1/replay-1pred-2cues-500trials-1-361393.pkl'\n",
    "MODEL_RE_2 = 'independent-2/model-1pred-2cues-500trials-2-327760.ckpt'\n",
    "REPLAY_RE_2 = 'independent-2/replay-1pred-2cues-500trials-2-327760.pkl'\n",
    "MODEL_RE_3 = 'independent-3/model-1pred-2cues-500trials-3-209602.ckpt'\n",
    "REPLAY_RE_3 = 'independent-3/replay-1pred-2cues-500trials-3-209602.pkl'\n",
    "MODEL_RE_4 = 'independent-4/model-1pred-2cues-500trials-4-361147.ckpt'\n",
    "REPLAY_RE_4 = 'independent-4/replay-1pred-2cues-500trials-4-361147.pkl'\n",
    "\n",
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "        \n",
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "        current_dir = os.getcwd()\n",
    "        all_replay = []\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_0\n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_0 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer[0])\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred1')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_1 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_1 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer[0])\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred2')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_2 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_2 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer[0])\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred3')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_3 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_3 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer[0])\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred4')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_4 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_4 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer[0])\n",
    "            \n",
    "\n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)\n",
    "        \n",
    "    # Save collisions\n",
    "    collisions_name = 'saved_graphs/' + COLLISIONS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(collisions_name, \"wb\") as f:\n",
    "        pickle.dump(g.collisions, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (dqn-multiagent)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
