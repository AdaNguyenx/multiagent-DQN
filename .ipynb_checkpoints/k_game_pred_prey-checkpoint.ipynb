{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/h8kgsfbd26q2jz0jslqn23mm0000gn/T/tmpm4hhx90n\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = tempfile.mkdtemp()\n",
    "print(LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cue (250, 200)\n",
    "radius 150\n",
    "prey first point (75-125, 175-225)\n",
    "pred (225-275, 225-275)\n",
    "observable 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 25), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'new'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5pred-2cues-500trials-80weight'\n",
    "REPLAY_NAME = 'replay-5pred-2cues-500trials-80weight'\n",
    "ELAPSE_NAME = 'elapse-5pred-2cues-500trials-80weight'\n",
    "REWARDS_NAME = 'rewards-5pred-2cues-500trials-80weight'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE = 'model-1-191685'\n",
    "REPLAY_RE = 'replay-1-191685'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:15,894] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:16,007] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:16,544] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:16,623] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:17,076] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:17,156] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:17,571] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:17,734] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:18,154] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-24 12:25:18,226] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    }
   ],
   "source": [
    "journalist = tf.summary.FileWriter(LOG_DIR)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['prey'] != 0:\n",
    "    if current_settings['network_prey'] == 'one':\n",
    "        network_prey = 1\n",
    "    else:\n",
    "        network_prey = current_settings['num_objects_active']['prey']\n",
    "\n",
    "    for i in range(network_prey):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_prey = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_prey,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)\n",
    "\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        replay_buffer = ReplayBuffer(50000)\n",
    "        all_replay.append(replay_buffer)\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Interrupted\n",
      "graphics shut down\n"
     ]
    }
   ],
   "source": [
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "#         # when only restoring a subset of variables\n",
    "#         restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "#         saver = tf.train.Saver(restore)\n",
    "\n",
    "        # reload models\n",
    "        saver = tf.train.Saver()\n",
    "        current_dir = os.getcwd()\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE + '.ckpt'\n",
    "        saver.restore(sess, model_name)\n",
    "        # reload replay buffers\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE + '.pkl'\n",
    "        with open(replay_name, 'rb') as f:\n",
    "            all_replay = pickle.load(f)\n",
    "            \n",
    "#         # remember to append buffer if restoring a subset of variables\n",
    "#         all_replay.append(replay_buffer)\n",
    "    \n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards,\n",
    "                 percent = 1)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save models    \n",
    "    model_name = 'saved_graphs/' + MODEL_NAME + '-' + str(timesteps[0]) + '.ckpt'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, model_name)\n",
    "    \n",
    "    # Save replay buffers\n",
    "    replay_name = 'saved_graphs/' + REPLAY_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(replay_name, \"wb\") as f:\n",
    "        pickle.dump(all_replay, f)\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFDYZsBaypoYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ad2c4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(elapsed, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FOR DEBUGGING\n",
    "# Visualize graph in TensorBoard\n",
    "tf.summary.FileWriter(LOG_DIR, tf.get_default_graph())\n",
    "\n",
    "# Get all current variables\n",
    "# tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (dqn-multiagent)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
