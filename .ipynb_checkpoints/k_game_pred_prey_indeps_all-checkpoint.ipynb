{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf_rl.controller import DiscreteDeepQ, ModelController\n",
    "from tf_rl.simulation import KarpathyGame\n",
    "from tf_rl import simulate\n",
    "from tf_rl.models import MLP\n",
    "from collections import OrderedDict\n",
    "from euclid import Vector2\n",
    "\n",
    "from baselines import deepq\n",
    "import baselines.common.tf_util as U\n",
    "from baselines.deepq.replay_buffer import ReplayBuffer\n",
    "from baselines.common.schedules import LinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/h8kgsfbd26q2jz0jslqn23mm0000gn/T/tmp_rm2kai8\n"
     ]
    }
   ],
   "source": [
    "LOG_DIR = tempfile.mkdtemp()\n",
    "print(LOG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cue (250, 200)\n",
    "radius 150\n",
    "prey first point (75-125, 175-225)\n",
    "pred (225-275, 225-275)\n",
    "observable 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_settings = {\n",
    "    #earlier objects are eaten by later objects (pred eat prey)\n",
    "    'objects': [\n",
    "        'prey',\n",
    "        'pred',\n",
    "        'cue',\n",
    "    ],\n",
    "    'colors': {\n",
    "        'prey': [212, 211, 208],\n",
    "        'pred':  [100, 37, 0],\n",
    "        'cue': [0,0,0],\n",
    "    },\n",
    "    'object_reward': {\n",
    "        'prey': {'prey': 0.1, 'pred': -0.1, 'cue': 0.0},\n",
    "        'pred': {'prey': 1.0, 'pred': -1.0, 'cue': 0.0},\n",
    "    },\n",
    "    'hero_bounces_off_walls': False,\n",
    "    'world_size': (500,300),   \n",
    "    \"maximum_velocity\":      {'prey': 0, 'pred': 50},\n",
    "    \"object_radius\": 10.0,\n",
    "    \"cue_types\": 2,\n",
    "    \"num_objects\": OrderedDict([('prey', 5), ('pred', 5), ('cue', 1)]),\n",
    "    # active means that the objects are learning\n",
    "    \"num_objects_active\": OrderedDict([('prey', 0), ('pred', 5)]), \n",
    "    #'multiple' to create each DQN for each prey/predator\n",
    "    #'one' to use one DQN for all preys/predators\n",
    "    # only really matters if the preys/predators are active\n",
    "    \"network_prey\": 'one',\n",
    "    \"network_pred\": 'multiple',\n",
    "    \"num_observation_lines\" : 32,\n",
    "    \"observation_line_length\": 75.,\n",
    "    \"tolerable_distance_to_wall\": 50,\n",
    "    \"wall_distance_penalty\":  -1.0,\n",
    "    \"delta_v\": 50\n",
    "}\n",
    "\n",
    "#'new' to create new sim with values above\n",
    "#'load' to load a previously trained graph\n",
    "RUN = 'load'  \n",
    "\n",
    "# First three for names for saving new runs\n",
    "MODEL_NAME = 'model-5indeps-100weight'\n",
    "REPLAY_NAME = 'replay-5indeps-100weight'\n",
    "ELAPSE_NAME = 'elapse-5indeps-100weight'\n",
    "REWARDS_NAME = 'rewards-5indeps-100weight'\n",
    "\n",
    "# Last two for names for reloading model/replay buffers\n",
    "MODEL_RE_0 = 'independent-0/model-1pred-2cues-500trials-340708.ckpt'\n",
    "REPLAY_RE_0 = 'independent-0/replay-1pred-2cues-500trials-340708.pkl'\n",
    "MODEL_RE_1 = 'independent-1/model-1pred-2cues-500trials-1-361393.ckpt'\n",
    "REPLAY_RE_1 = 'independent-1/replay-1pred-2cues-500trials-1-361393.pkl'\n",
    "MODEL_RE_2 = 'independent-2/model-1pred-2cues-500trials-2-327760.ckpt'\n",
    "REPLAY_RE_2 = 'independent-2/replay-1pred-2cues-500trials-2-327760.pkl'\n",
    "MODEL_RE_3 = 'independent-3/model-1pred-2cues-500trials-3-209602.ckpt'\n",
    "REPLAY_RE_3 = 'independent-3/replay-1pred-2cues-500trials-3-209602.pkl'\n",
    "MODEL_RE_4 = 'independent-4/model-1pred-2cues-500trials-4-361147.ckpt'\n",
    "REPLAY_RE_4 = 'independent-4/replay-1pred-2cues-500trials-4-361147.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create the game simulator\n",
    "g = KarpathyGame(current_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:26:58,417] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:26:58,501] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:26:59,032] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:26:59,116] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:26:59,551] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:26:59,639] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:00,067] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:00,249] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:00,697] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:00,774] VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    }
   ],
   "source": [
    "journalist = tf.summary.FileWriter(LOG_DIR)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "all_act = []\n",
    "all_train = []\n",
    "all_update = []\n",
    "all_debug = []\n",
    "all_replay = []\n",
    "\n",
    "# Build graphs\n",
    "if current_settings['num_objects_active']['pred'] != 0:\n",
    "    if current_settings['network_pred'] == 'one':\n",
    "        network_pred = 1\n",
    "    else:\n",
    "        network_pred = current_settings['num_objects_active']['pred']\n",
    "\n",
    "    for i in range(network_pred):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            brain_pred = deepq.models.mlp([200, 200])\n",
    "            act, train, update_target, debug = deepq.build_train(\n",
    "                make_obs_ph=lambda name: U.BatchInput((g.observation_size,), name=name),\n",
    "                q_func=brain_pred,\n",
    "                num_actions=g.num_actions,\n",
    "                optimizer=tf.train.AdamOptimizer(learning_rate=5e-4),\n",
    "            )\n",
    "        all_act.append(act)\n",
    "        all_train.append(train)\n",
    "        all_update.append(update_target)\n",
    "        all_debug.append(debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-0/model-1pred-2cues-500trials-340708.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:02,712] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-0/model-1pred-2cues-500trials-340708.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-1/model-1pred-2cues-500trials-1-361393.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:03,656] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-1/model-1pred-2cues-500trials-1-361393.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-2/model-1pred-2cues-500trials-2-327760.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:04,542] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-2/model-1pred-2cues-500trials-2-327760.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-3/model-1pred-2cues-500trials-3-209602.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:05,488] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-3/model-1pred-2cues-500trials-3-209602.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-4/model-1pred-2cues-500trials-4-361147.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-25 14:27:06,661] Restoring parameters from /Users/Linhchi/dqlearn_multiagent/summer17-python3/saved_graphs/independent-4/model-1pred-2cues-500trials-4-361147.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-62f5b5b1e366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m                  \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                  \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melapsed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                  all_rewards = rewards)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dqlearn_multiagent/summer17-python3/tf_rl/simulate.py\u001b[0m in \u001b[0;36msimulate\u001b[0;34m(simulation, replay, act, train, update, debug, fps, visualize_every, action_every, simulation_resolution, wait, disable_training, save_path, timesteps, elapsed, all_rewards, percent)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;31m# store last transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mreplay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_observation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_action\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_observation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# update current state as last state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "FPS          = 30\n",
    "ACTION_EVERY = 3\n",
    "    \n",
    "fast_mode = False\n",
    "if fast_mode:\n",
    "    WAIT, VISUALIZE_EVERY = False, 100\n",
    "else:\n",
    "    WAIT, VISUALIZE_EVERY = True, 1\n",
    "\n",
    "elapsed = []\n",
    "rewards = []\n",
    "timesteps = [0]\n",
    "    \n",
    "# Initializing or reloading variables\n",
    "# Start TensorFlow session with 2 CPUs\n",
    "with U.make_session(2) as sess:\n",
    "    \n",
    "    # Initialize the parameters and copy them to the target network.\n",
    "    U.initialize()\n",
    "    for i in range(current_settings['num_objects_active']['prey']):\n",
    "        name = 'prey' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "    for i in range(current_settings['num_objects_active']['pred']):\n",
    "        name = 'pred' + str(i)\n",
    "        with tf.variable_scope(name):\n",
    "            update_target()\n",
    "            \n",
    "    if RUN == 'load':\n",
    "        current_dir = os.getcwd()\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred0')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_0\n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_0 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer)\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred1')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_1 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_1 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer)\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred2')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_2 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_2 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer)\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred3')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_3 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_3 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer)\n",
    "        \n",
    "        # pred0\n",
    "        restore = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = 'pred4')\n",
    "        saver = tf.train.Saver(restore)\n",
    "        model_name = current_dir + '/saved_graphs/' + MODEL_RE_4 \n",
    "        saver.restore(sess, model_name)\n",
    "        replay_name = current_dir + '/saved_graphs/' + REPLAY_RE_4 \n",
    "        with open(replay_name, 'rb') as f:\n",
    "            replay_buffer = pickle.load(f)\n",
    "        all_replay.append(replay_buffer)\n",
    "            \n",
    "\n",
    "    # Run simulation\n",
    "    try:\n",
    "        simulate(simulation=g,\n",
    "                 replay = all_replay,\n",
    "                 act = all_act,\n",
    "                 train = all_train,\n",
    "                 update = all_update,\n",
    "                 debug = all_debug,\n",
    "                 fps=FPS,\n",
    "                 visualize_every=VISUALIZE_EVERY,\n",
    "                 action_every=ACTION_EVERY,\n",
    "                 wait=WAIT,\n",
    "                 disable_training=False,\n",
    "                 simulation_resolution=.001,\n",
    "                 save_path=None,\n",
    "                 timesteps = timesteps,\n",
    "                 elapsed = elapsed,\n",
    "                 all_rewards = rewards)\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "        g.shut_down_graphics()\n",
    "        print('graphics shut down')\n",
    "        \n",
    "    # Save models    \n",
    "    model_name = 'saved_graphs/' + MODEL_NAME + '-' + str(timesteps[0]) + '.ckpt'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, model_name)\n",
    "    \n",
    "    # Save replay buffers\n",
    "    replay_name = 'saved_graphs/' + REPLAY_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(replay_name, \"wb\") as f:\n",
    "        pickle.dump(all_replay, f)\n",
    "        \n",
    "    # Save trial times\n",
    "    elapse_name = 'saved_graphs/' + ELAPSE_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(elapse_name, \"wb\") as f:\n",
    "        pickle.dump(elapsed, f)\n",
    "        \n",
    "    # Save rewards\n",
    "    rewards_name = 'saved_graphs/' + REWARDS_NAME + '-' + str(timesteps[0]) + '.pkl'\n",
    "    with open(rewards_name, \"wb\") as f:\n",
    "        pickle.dump(rewards, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<baselines.deepq.replay_buffer.ReplayBuffer at 0x11f9c9a20>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_replay[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(elapsed, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FOR DEBUGGING\n",
    "# Visualize graph in TensorBoard\n",
    "tf.summary.FileWriter(LOG_DIR, tf.get_default_graph())\n",
    "\n",
    "# Get all current variables\n",
    "# tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (dqn-multiagent)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
